{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491646f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6875242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import json, os, pickle, glob\n",
    "import tqdm\n",
    "import corner\n",
    "import scipy.linalg as sl\n",
    "import logging\n",
    "from IPython.display import display, Math\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23448fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import la_forge.diagnostics as dg\n",
    "import la_forge.core as co\n",
    "from la_forge.rednoise import gorilla_bf\n",
    "from la_forge.utils import epoch_ave_resid\n",
    "from h5pulsar import FilePulsar\n",
    "from enterprise.signals.utils import ConditionalGP\n",
    "#from la_forge.gp import Signal_Reconstruction\n",
    "import enterprise.constants as const\n",
    "from enterprise_extensions.empirical_distr import EmpiricalDistribution1D, EmpiricalDistribution2D\n",
    "#from collections import OrderedDict\n",
    "#DM_K = float(2.41e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dr3_noise import post_processing_utils as ppu\n",
    "from dr3_noise import plot_utils as pu\n",
    "from dr3_noise.models import model_singlepsr_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c762ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_post_and_set_burn(cs, nchains, param='lnpost', fig_savedir=None,\n",
    "                           min_burn=500, max_burn=10000, adapt_burnin=False,\n",
    "                           single_core_burns=[]):\n",
    "    total_samples = 0\n",
    "    total_postburn_samples = 0\n",
    "    fig, ax = plt.subplots(2,1,figsize=(12,6),sharex=False)\n",
    "    i = 0\n",
    "    for _ in range(nchains):\n",
    "        if adapt_burnin:\n",
    "            idx_bad = np.where(cs[i]('lnpost', to_burn=False) < np.max(cs[i]('lnpost'))-200)[0][-1]\n",
    "            min_burn = np.max([min_burn,idx_bad+1000])\n",
    "        burn = np.min([np.max([min_burn, len(cs[i].chain)//4]), max_burn])\n",
    "        for single_core_burn in single_core_burns:\n",
    "            if single_core_burn[0] == i:\n",
    "                burn = single_core_burn[1]\n",
    "        cs[i].set_burn(burn)\n",
    "        n_samples = len(cs[i].get_param(param,to_burn=True))\n",
    "        x = np.arange(np.ceil(total_postburn_samples),\n",
    "                      np.ceil(total_postburn_samples)+np.ceil(n_samples))\n",
    "        y = cs[i].get_param(param,to_burn=True)\n",
    "        ax[0].plot(y, alpha=0.2, lw=0.5, c='k')\n",
    "        if n_samples < 100:\n",
    "            print(f'no samples for cs[{i}]')\n",
    "            cs.pop(i)\n",
    "            nchains -= 1\n",
    "        else:\n",
    "            total_postburn_samples += n_samples\n",
    "            total_samples += len(cs[i].get_param(param,to_burn=False))\n",
    "            ax[1].plot(x,y,lw=0.5)\n",
    "            i += 1\n",
    "    if len(cs) == 0:\n",
    "        return 0\n",
    "    ax[0].set_ylabel(param)\n",
    "    ax[0].set_title(cs[0].label)\n",
    "    ax[1].set_ylabel(param)\n",
    "    ax[-1].set_xlabel('sample')\n",
    "    fig.tight_layout()\n",
    "    if fig_savedir:\n",
    "        fig.savefig(f'{fig_savedir}/{param}_trace.png')\n",
    "\n",
    "    print(f'burns: {[c.burn for c in cs]}')\n",
    "    print(total_samples,'total samples')\n",
    "    print(total_postburn_samples,'samples after burn in')\n",
    "    print(np.round((total_samples-total_postburn_samples)*100/total_samples,3),'% of samples burned')\n",
    "    return nchains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c985480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nmodel_traces(cs, fig_savedir):\n",
    "    total_samples = 0\n",
    "    total_postburn_samples = 0\n",
    "    fig, ax = plt.subplots(2,1,figsize=(12,6),sharex=False)\n",
    "    for i in range(len(cs)):\n",
    "        n_samples = len(cs[i].get_param('nmodel',to_burn=True))\n",
    "        x = np.arange(np.ceil(total_postburn_samples),\n",
    "                      np.ceil(total_postburn_samples)+np.ceil(n_samples))\n",
    "        y1 = cs[i].get_param('nmodel',to_burn=False)\n",
    "        ax[0].plot(y1, alpha=0.2, lw=0.5, c='k')\n",
    "        ax[0].axvline(cs[i].burn, color='k', lw=1, ls='dashed', alpha=0.3)\n",
    "        total_postburn_samples += n_samples\n",
    "        total_samples += len(cs[i].get_param('nmodel',to_burn=True))\n",
    "        y2 = cs[i].get_param('nmodel',to_burn=True)\n",
    "        ax[1].plot(x,y2,lw=0.5)\n",
    "    for i in range(2):\n",
    "        ax[i].set_yticks(np.arange(cs[0].nmodels))\n",
    "        ax[i].set_yticklabels(['CRN','HD'])\n",
    "        for j in range(cs[0].nmodels+1):\n",
    "            ax[i].axhline(j-0.5, lw=0.5, linestyle='dashed', color='k')\n",
    "        ax[i].set_ylim([-0.5, cs[0].nmodels-0.5])\n",
    "        ax[i].set_ylabel('model')\n",
    "    ax[0].set_title(cs[0].label)\n",
    "    ax[-1].set_xlabel('sample')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{fig_savedir}/nmodel_trace.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4caca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proposals(core,ylim=None,ax=None,return_fig=False):\n",
    "    if ax == None:\n",
    "        return_ax = True\n",
    "        fig, ax = plt.subplots(figsize=[8,7])\n",
    "    else:\n",
    "        return_ax = False\n",
    "    # L = len(c1.jumps.keys())\n",
    "    # half = L//2\n",
    "\n",
    "    for ii,ky in enumerate(core.jumps.keys()):\n",
    "        if ii>=9:\n",
    "            ls='--'\n",
    "        else:\n",
    "            ls='-'\n",
    "        if (ky=='jumps'):# or (ky=='DEJump_jump'):\n",
    "            pass\n",
    "        else:\n",
    "            if ky[0]=='c':\n",
    "                lab = 'SCAM' if 'SCAM' in ky else 'AM'\n",
    "            elif ky=='DEJump_jump':\n",
    "                lab = 'DEJump'\n",
    "            else:\n",
    "                lab = ' '.join(np.array(ky.split('_'))[2:-1])\n",
    "                if 'gwb' in lab:\n",
    "                    lab = 'gwb log-uniform'\n",
    "            if lab == 'DEJump':\n",
    "                deL = core.jumps[ky].size\n",
    "                jL = core.jumps['covarianceJumpProposalAM_jump'].size\n",
    "\n",
    "                nums = np.linspace(jL-deL,jL-1,deL)\n",
    "                ax.plot(nums,core.jumps[ky],label=lab,\n",
    "                        ls=ls,lw=2,color='C'+str(ii))\n",
    "            else:\n",
    "                ax.plot(core.jumps[ky],label=lab,\n",
    "                        ls=ls,lw=2,color='C'+str(ii))\n",
    "    if return_ax:\n",
    "        ax.grid()\n",
    "        if ylim is not None:\n",
    "            ax.set_ylim(**ylim)\n",
    "        ax.legend(loc='upper left',ncol=2,fontsize=11)\n",
    "        ax.set_ylabel('Acceptance Rate',fontsize=14)\n",
    "        ax.set_xlabel('Write Out Iteration',fontsize=14)\n",
    "        ax.set_title('Jump Proposal Acceptance Rates')\n",
    "        if return_fig:\n",
    "            return fig, ax\n",
    "        else:\n",
    "            return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29a1c7",
   "metadata": {},
   "source": [
    "# Load chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'lite_unfiltered_53'\n",
    "Nfreqs = 13\n",
    "noisetype = 'advnoise'\n",
    "chain_name = f'HM_CRN{Nfreqs}_g4p3_{noisetype}'\n",
    "model_name = f'HM_GWB{Nfreqs}_g4p3_{noisetype}'\n",
    "# ------------\n",
    "# specify pulsar, dataset, model, and number of cores\n",
    "project_path = '/vast/palmer/home.grace/bbl29/IPTA_DR2_analysis'\n",
    "# where chains are stored\n",
    "if dataset == 'edr2':\n",
    "    chaindir = f'/vast/palmer/scratch/mingarelli/bbl29/IPTA_DR2_analysis/chains/edr2/{chain_name}'\n",
    "    coresave = f'/vast/palmer/home.grace/bbl29/project/IPTA_DR2_analysis/edr2/{model_name}'\n",
    "    figsave = f'{project_path}/figs/edr2/{model_name}'\n",
    "else:\n",
    "    chaindir = f'/vast/palmer/scratch/mingarelli/bbl29/IPTA_DR2_analysis/chains/dr2{dataset}/{chain_name}'\n",
    "    coresave = f'/vast/palmer/home.grace/bbl29/project/IPTA_DR2_analysis/dr2{dataset}/{model_name}'\n",
    "    figsave = f'{project_path}/figs/dr2{dataset}/{model_name}'\n",
    "ePSR_dir = f'{project_path}/data/{dataset}_ePSRs'\n",
    "load_pt_chains = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ee2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(chaindir):\n",
    "    raise NameError(f'chaindir does not exist!!')\n",
    "if not os.path.isdir(coresave):\n",
    "    os.mkdir(coresave)\n",
    "if not os.path.isdir(figsave):\n",
    "    os.mkdir(figsave)\n",
    "\n",
    "chaindirs = [x[0]+'/' for x in os.walk(chaindir)][1:]\n",
    "nchains = len(chaindirs)\n",
    "\n",
    "cs = []\n",
    "for cd in tqdm.tqdm(chaindirs):\n",
    "    #if i == 0:\n",
    "    #    continue\n",
    "    #print(f'{i+1}/{nchains}')\n",
    "    try:\n",
    "        with open(f'{cd}/model_params.json', 'r') as f:\n",
    "            hm_params = json.load(f)\n",
    "        with open(f'{cd}/model_labels.json', 'r') as f:\n",
    "            hm_labels = json.load(f)\n",
    "        core = co.HyperModelCore(label=f'HM GWB13 g4p3 {noisetype}', param_dict=hm_params,\n",
    "                                 chaindir=cd, pt_chains=load_pt_chains)\n",
    "        # load weights\n",
    "        if len(core.chain) > 200:\n",
    "            cs.append(core)\n",
    "    except Exception as e:\n",
    "        print(f'could not load from {cd}')\n",
    "        print(f'Exception: {e}')\n",
    "del core\n",
    "nchains = len(cs)\n",
    "if nchains == 0:\n",
    "    print(f'Not enough samples!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cs:\n",
    "    print(c.chain.shape)\n",
    "    if not 'lnpost' in c.params:\n",
    "        c.params += ['lnlike', 'lnpost', 'chain_accept', 'pt_chain_accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_bad = cs.pop(2)\n",
    "nchains -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a010f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nchains = plot_post_and_set_burn(cs, nchains, fig_savedir=figsave,\n",
    "                                 min_burn=500, max_burn=20000, adapt_burnin=True)#,\n",
    "#                                 single_core_burns=[[0,20000],[3,25000]])\n",
    "if nchains == 0:\n",
    "    print(f'Not enough samples!!')\n",
    "else:\n",
    "    plot_nmodel_traces(cs, fig_savedir=figsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44043eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot proposals\n",
    "fig, ax = plot_proposals(cs[0],return_fig=True)\n",
    "for i in range(nchains):\n",
    "    plot_proposals(cs[i], ax=ax)\n",
    "fig.savefig(f'{figsave}/proposals.png')\n",
    "pars = cs[0].params[:15] + [p for p in cs[0].params if 'dip' in p] + cs[0].params[-7:]\n",
    "dg.plot_chains(cs, pars=pars, hist=True, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a66616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make core with all cores together\n",
    "chains = []\n",
    "hot_chains = {}\n",
    "for ci in cs:\n",
    "    chains.append(ci.chain[ci.burn::])\n",
    "chain_array = np.concatenate(chains)\n",
    "c = co.HyperModelCore(chain=chain_array, label=cs[0].label, param_dict=hm_params,\n",
    "                      params=cs[0].params, pt_chains=False, burn=0)\n",
    "# add priors\n",
    "prior_path = glob.glob(chaindir + '/*/priors.txt')[0]\n",
    "c.priors = np.loadtxt(prior_path, dtype=str, delimiter='\\t')\n",
    "# add runtime info\n",
    "info_path = glob.glob(chaindir + '/*/runtime_info.txt')[0]\n",
    "c.runtime_info = np.loadtxt(info_path, dtype=str, delimiter='\\t')\n",
    "# add hot chains\n",
    "if load_pt_chains:\n",
    "    for T in cs[0].hot_chains:\n",
    "        hot_chains[T] = []\n",
    "        for ci in cs:\n",
    "            hot_chains[T].append(ci.hot_chains[T][ci.burn::])\n",
    "        hot_chains[T] = np.concatenate(hot_chains[T])\n",
    "    c.hot_chains = hot_chains\n",
    "c.save(f'{coresave}/core.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = co.HyperModelCore(corepath=f'{coresave}/core.h5', burn=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b176246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enterprise_extensions.model_utils import odds_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF, BF_err = odds_ratio(c('nmodel'))\n",
    "display(Math(fr'\\mathcal{{B}}^{{\\rm{{HD}}}}_{{\\rm{{CRN}}}} = {BF:0.3f} \\pm {BF_err:0.3f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c4f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dg.plot_chains([c.model_core(i) for i in range(2)],legend_labels=['CARN','HD'], ncols=5,\n",
    "               pars=c.params[:20] + ['lnlike'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcbb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dg.plot_grubin(c)\n",
    "dg.plot_neff(c)\n",
    "#if ppu.check_convergence(c, psrname=model_name, plot=True, Nsample_threshold=50000):\n",
    "#    print(f'Convergence passed!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,2), dpi=500)\n",
    "ax.hist(c.model_core(0)('crn_log10_A'), histtype='step', density=True, bins=30, label='Auto correlations only')\n",
    "ax.hist(c.model_core(1)('gwb_log10_A'), histtype='step', density=True, bins=30, label='Auto+cross correlations')\n",
    "ax.set_xlabel(r'$\\log_{10}A_{\\rm{CRN}}$')\n",
    "ax.set_ylabel('PDF')\n",
    "ax.legend(fontsize='xx-small')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'{figsave}/HM_gwb_log10_A.png', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753c6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba149b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faead9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9502ba4",
   "metadata": {},
   "source": [
    "### Pulsar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(params, psrname, add_psrname=True):\n",
    "    labels = []\n",
    "    if add_psrname:\n",
    "        add = psrname+'\\n'\n",
    "    else:\n",
    "        add = ''\n",
    "    for p in params:\n",
    "        if 'dm_gp_gamma' in p:\n",
    "            labels.append(add+r'$\\gamma_{\\rm{DM}}$')\n",
    "        elif 'dm_gp_log10_A' in p:\n",
    "            labels.append(add+r'$\\log_{10}A_{\\rm{DM}}$')\n",
    "        elif 'red_noise_gamma' in p:\n",
    "            labels.append(add+r'$\\gamma_{\\rm{RN}}$')\n",
    "        elif 'red_noise_log10_A' in p:\n",
    "            labels.append(add+r'$\\log_{10}A_{\\rm{RN}}$')\n",
    "        elif p == 'crn_log10_A':\n",
    "            labels.append(r'$\\log_{10}A_{\\rm{CRN}}$')\n",
    "        elif 'exp1_log10_Amp' in p:\n",
    "            labels.append(add+r'$\\log_{10}A_{\\rm{exp}}$')\n",
    "        elif 'exp1_log10_tau' in p:\n",
    "            labels.append(add+r'$\\log_{10}\\tau_{\\rm{exp}}$')\n",
    "        elif 'exp1_t0' in p:\n",
    "            labels.append(add+r'$t_{\\rm{exp}}$')\n",
    "        else:\n",
    "            labels.append(p)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a81a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "psrnames = np.unique([p.split('_')[0] for p in c.params if 'J' in p])\n",
    "for psrname in psrnames:\n",
    "    corepath = f'/vast/palmer/home.grace/bbl29/project/IPTA_DR2_analysis/dr2full/advnoise/{psrname}/core.h5'\n",
    "    c_psr = co.Core(corepath=corepath, burn=0)\n",
    "    # first make a corner plot with the full run on it, minus the Common red noise\n",
    "    params = [p for p in c.params if psrname in p]# + ['crn_log10_A']\n",
    "    p_idxs = [c.params.index(p) for p in params]\n",
    "    labels = make_labels(params, psrname, add_psrname=False)\n",
    "    fig = corner.corner(c.chain[:,p_idxs], levels=(0.68,0.95), labels=labels,\n",
    "                        color='k', plot_density=False, plot_datapoints=False,\n",
    "                        no_fill_contours=True, hist_kwargs={'density':True},\n",
    "                        label_kwargs={'fontsize':20})\n",
    "    # next add single pulsar run\n",
    "    p_psr_idxs = [c_psr.params.index(p) for p in params]\n",
    "    fig = corner.corner(c_psr.chain[:,p_psr_idxs], levels=(0.68,0.95), fig=fig,\n",
    "                        color='C0', plot_density=False, plot_datapoints=False,\n",
    "                        no_fill_contours=True, hist_kwargs={'density':True})\n",
    "    # finally add CRN onto intrinsic red noise plot\n",
    "    ndim = len(params)\n",
    "    axes = np.reshape(fig.axes, (ndim,ndim))\n",
    "    idx_crn = c.params.index('crn_log10_A')\n",
    "    axes[-1,-1].hist(c.chain[:,idx_crn], color='C1',\n",
    "                     density=True, bins=20, histtype='step')\n",
    "    # add 13/3 line\n",
    "    axes[-1,-2].axvline(13/3, color='C1', ls='dashed')\n",
    "    axes[-2,-2].axvline(13/3, color='C1', ls='dashed')\n",
    "    lines = [mlines.Line2D([],[],color='C0',label='Single run')]\n",
    "    lines += [mlines.Line2D([],[],color='k',label='PTA run')]\n",
    "    lines += [mlines.Line2D([],[],color='C1',label='CRN')]\n",
    "    fig.legend(handles=lines, fontsize=20)\n",
    "    fig.suptitle(f'PSR {psrname}', fontsize=30)\n",
    "    fig.savefig(f'{figsave}/{psrname}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's identify pulsars with significant RN whose RN is no longer significant\n",
    "fig, ax = plt.subplots(figsize=(9,7))\n",
    "i = 0\n",
    "lines = []\n",
    "for psrname in psrnames:\n",
    "    corepath = f'/vast/palmer/home.grace/bbl29/project/IPTA_DR2_analysis/dr2full/stdnoise/{psrname}/core.h5'\n",
    "    c_psr = co.Core(corepath=corepath, burn=0)\n",
    "    x = c_psr(f'{psrname}_red_noise_gamma')\n",
    "    y = c_psr(f'{psrname}_red_noise_log10_A')\n",
    "    BF = gorilla_bf(y, min=-20, max=-11)\n",
    "    BF_new = gorilla_bf(c(f'{psrname}_red_noise_log10_A'), min=-20, max=-11)\n",
    "    if (np.isnan(BF) or BF > 10) and (BF_new < 10):\n",
    "        print(f'adding {psrname}')\n",
    "        corner.hist2d(x, y, fig=fig, levels=(0.68,), color=f'C{i}',\n",
    "                      plot_density=False, no_fill_contours=True, plot_datapoints=False,\n",
    "                      contour_kwargs={'lw':1,'alpha':1})\n",
    "        lines.append(mlines.Line2D([],[],color=f'C{i}',label=psrname))\n",
    "        i += 1\n",
    "ymed = c.get_param_median('crn_log10_A')\n",
    "ylo = c.get_param_credint('crn_log10_A', interval=95)[0]\n",
    "yhi = c.get_param_credint('crn_log10_A', interval=95)[1]\n",
    "ax.errorbar(x=[13/3], y=[ymed], yerr=[[ymed-ylo],[yhi-ymed]], fmt='sk', ms=5)\n",
    "ax.set_xlabel(r'$\\gamma_{\\rm{RN}}$')\n",
    "ax.set_ylabel(r'$\\log_{10}A_{\\rm{RN}}$')\n",
    "ax.set_xlim([0,7])\n",
    "ax.set_ylim([-17,-11])\n",
    "ax.set_title('Red noise posteriors (pulsars contributing to CP)')\n",
    "ax.grid(lw=0.3)\n",
    "ax.legend(handles=lines, fontsize='small')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de4a0da",
   "metadata": {},
   "source": [
    "# Make empirical distributions\n",
    "\n",
    "Need list of the following:\n",
    "- 2D dist for RN for each pulsars\n",
    "- 2D dist for DM for each pulsar\n",
    "- 1D dists for dip params for J1713\n",
    "- 2D dist for common red noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_distributions(c, psrnames, burn=0, nbins=40,\n",
    "                                 filename=None, return_distribution=False):\n",
    "    \n",
    "    distr = []\n",
    "    paramlist = []\n",
    "    \n",
    "    i = 0\n",
    "    for psrname in psrnames:\n",
    "        \n",
    "        # make param list\n",
    "        paramlist.append([f'{psrname}_red_noise_gamma',f'{psrname}_red_noise_log10_A'])\n",
    "        paramlist.append([f'{psrname}_dm_gp_gamma',f'{psrname}_dm_gp_log10_A'])\n",
    "        if psrname == 'J1713+0747':\n",
    "            paramlist.append([f'{psrname}_exp1_log10_Amp'])\n",
    "            paramlist.append([f'{psrname}_exp1_log10_tau'])\n",
    "            paramlist.append([f'{psrname}_exp1_t0'])\n",
    "\n",
    "    paramlist.append(['crn_log10_A'])\n",
    "\n",
    "    for pl in paramlist:\n",
    "\n",
    "        if type(pl) is not list:\n",
    "\n",
    "            pl = [pl]\n",
    "\n",
    "        if len(pl) == 1:\n",
    "            idx = c.params.index(pl[0])\n",
    "\n",
    "            prior_min = float(c.priors[idx][c.priors[idx].index('pmin')+5:c.priors[idx].index(',')])\n",
    "            prior_max = float(c.priors[idx][c.priors[idx].index('pmax')+5:c.priors[idx].index(')')])\n",
    "\n",
    "            # get the bins for the histogram\n",
    "            bins = np.linspace(prior_min, prior_max, nbins)\n",
    "\n",
    "            new_distr = EmpiricalDistribution1D(pl[0], c.chain[c.burn:, idx], bins)\n",
    "\n",
    "            distr.append(new_distr)\n",
    "\n",
    "        elif len(pl) == 2:\n",
    "\n",
    "            # get the parameter indices\n",
    "            idx = [c.params.index(pl1) for pl1 in pl]\n",
    "\n",
    "            # get the bins for the histogram\n",
    "            bins = [np.linspace(float(c.priors[i][c.priors[i].index('pmin')+5:c.priors[i].index(',')]),\n",
    "                                float(c.priors[i][c.priors[i].index('pmax')+5:c.priors[i].index(')')]),\n",
    "                                nbins) for i in idx]\n",
    "\n",
    "            new_distr = EmpiricalDistribution2D(pl, c.chain[c.burn:, idx].T, bins)\n",
    "\n",
    "            distr.append(new_distr)\n",
    "\n",
    "        else:\n",
    "            msg = 'WARNING: only 1D and 2D empirical distributions are currently allowed.'\n",
    "            logger.warning(msg)\n",
    "\n",
    "    # save the list of empirical distributions as a pickle file\n",
    "    if filename is not None:\n",
    "        if len(distr) > 0:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(distr, f)\n",
    "\n",
    "            msg = 'The empirical distributions have been pickled to {0}.'.format(filename)\n",
    "            logger.info(msg)\n",
    "        else:\n",
    "            msg = 'WARNING: No empirical distributions were made!'\n",
    "            logger.warning(msg)\n",
    "\n",
    "    if return_distribution:\n",
    "        return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5254f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{project_path}/empdists/dr2full_crn_stdnoise.pkl'\n",
    "distr = make_empirical_distributions(c, psrnames, burn=0, nbins=40,\n",
    "                                     filename=filename, return_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc27936",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeed812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef8140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e167f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14156f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60d8ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remake the whitened residuals plots so they are all in one place\n",
    "for psrname in psrs_done:\n",
    "    print(psrname)\n",
    "    c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5')\n",
    "    fname = f'{ePSR_dir}/{psrname}.hdf5'\n",
    "    psr = FilePulsar(fname)\n",
    "    # set up noise flags + selections\n",
    "    inc_ecorr = False\n",
    "    signal_names = [f'{psrname}_dm_gp',f'{psrname}_red_noise']\n",
    "    colors = ['C1','C3']\n",
    "    # set up DM Nfreqs\n",
    "    pta = model_singlepsr_noise(psr, Tspan=952746385.6296968,\n",
    "                                # timing -  set svd false for GPs\n",
    "                                tm_svd=False,\n",
    "                                # white noise - set gp_ecorr True for GPs\n",
    "                                tnequad=True, inc_ecorr=inc_ecorr, gp_ecorr=True,\n",
    "                                #efeq_groups=efeq_groups_by_PTA, ecorr_groups=ecorr_groups_by_PTA,\n",
    "                                log_equad_min=-10, log_equad_max=-4,\n",
    "                                # DM\n",
    "                                dm_var=True, dm_type='gp',\n",
    "                                dmgp_kernel='diag', dm_psd='powerlaw',\n",
    "                                dm_Nfreqs=30,\n",
    "                                # solar wind\n",
    "                                dm_sw_deter=False,\n",
    "                                # dm dip\n",
    "                                dm_expdip=dm_expdip, dm_expdip_basename='exp',\n",
    "                                dm_expdip_tau_min=np.log10(5), dm_expdip_tau_max=np.log10(500), \n",
    "                                # red noise\n",
    "                                log_A_min=-20, log_A_max=-11)\n",
    "    for signal in pta.signals:\n",
    "        if pta.signals[signal].signal_type == 'basis':\n",
    "            pta.signals[signal].basis_combine=False\n",
    "    n_realizations = 500\n",
    "    pu.plot_gp_realizations(c, psr, pta,\n",
    "                            signal_names, colors, method='enterprise',\n",
    "                            n_realizations=n_realizations,\n",
    "                            alpha=0.02, save=figsave)\n",
    "    idxs = np.random.choice(np.arange(len(c('lnpost'))), n_realizations)\n",
    "    gp = ConditionalGP(pta)\n",
    "    mlv_params = {p:c(p)[c.map_idx] for p in c.params}\n",
    "    mlv_GPs = gp.sample_processes(mlv_params, n=1)[0]\n",
    "    mlv_correction = np.sum([mlv_GPs[sn] for sn in mlv_GPs], axis=0)\n",
    "    pu.plot_resids(psr, correction=mlv_correction, save=f'{figsave_dir}/{psrname}',\n",
    "                   correction_label='_enterprise_ConditionalGP_MLV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corner import hist2d\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b25815",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,7))\n",
    "i = 0\n",
    "lines = []\n",
    "for psrname in psrnames:\n",
    "    c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5', burn=0)\n",
    "    x = c(f'{psrname}_red_noise_gamma')\n",
    "    y = c(f'{psrname}_red_noise_log10_A')\n",
    "    BF = gorilla_bf(y, min=-20, max=-11)\n",
    "    if np.isnan(BF) or BF > 10:\n",
    "        hist2d(x, y, fig=fig, levels=(0.68,), color=f'C{i}',\n",
    "               plot_density=False, no_fill_contours=True, plot_datapoints=False,\n",
    "               contour_kwargs={'lw':1,'alpha':1})\n",
    "        lines.append(mlines.Line2D([],[],color=f'C{i}',label=psrname))\n",
    "        i += 1\n",
    "ax.set_xlabel(r'$\\gamma_{\\rm{RN}}$')\n",
    "ax.set_ylabel(r'$\\log_{10}A_{\\rm{RN}}$')\n",
    "ax.set_xlim([0,7])\n",
    "ax.set_ylim([-17,-11])\n",
    "ax.set_title('Red noise posteriors')\n",
    "ax.grid(lw=0.3)\n",
    "ax.legend(handles=lines, fontsize='small')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc87a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,7))\n",
    "i = 0\n",
    "lines = []\n",
    "for psrname in psrnames:\n",
    "    c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5', burn=0)\n",
    "    x = c(f'{psrname}_dm_gp_gamma')\n",
    "    y = c(f'{psrname}_dm_gp_log10_A')\n",
    "    BF = gorilla_bf(y, min=-20, max=-11)\n",
    "    if np.isnan(BF) or BF > 10:\n",
    "        hist2d(x, y, fig=fig, levels=(0.68,), color=f'C{i}',\n",
    "               plot_density=False, no_fill_contours=True, plot_datapoints=False,\n",
    "               contour_kwargs={'lw':1,'alpha':1})\n",
    "        lines.append(mlines.Line2D([],[],color=f'C{i}',label=psrname))\n",
    "        i += 1\n",
    "ax.set_xlabel(r'$\\gamma_{\\rm{DM}}$')\n",
    "ax.set_ylabel(r'$\\log_{10}A_{\\rm{DM}}$')\n",
    "ax.set_title('DM noise posteriors')\n",
    "ax.set_xlim([0,7])\n",
    "ax.set_ylim([-17,-11])\n",
    "ax.grid(lw=0.3)\n",
    "ax.legend(handles=lines, fontsize='small')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "psrname = 'J1713+0747'\n",
    "c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5')\n",
    "pu.make_correlated_noise_corners(c, plot_ml_values=False, plot_med_values=True,\n",
    "                                 noise_types=['red_noise','dm_gp','exp1'],\n",
    "                                 save=f'{figsave_dir}/{psrname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bbc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsave_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fd7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba0098",
   "metadata": {},
   "source": [
    "# Make noise dictionary\n",
    "\n",
    "Here we will use median values to match DR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dict = {}\n",
    "for psrname in psrnames:\n",
    "    c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5', burn=0)\n",
    "    for p in c.params[:-4]:\n",
    "        noise_dict[p] = c.get_param_median(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{project_path}/noisedicts/dr2full_stdnoise.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(noise_dict, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b02d7",
   "metadata": {},
   "source": [
    "# Make empirical distributions\n",
    "\n",
    "Need list of the following:\n",
    "- 2D dist for RN for each pulsars\n",
    "- 2D dist for DM for each pulsar\n",
    "- 1D dists for dip params for J1713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2d5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psrname = 'J1713+0747'\n",
    "c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc82fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we need to make a chain with all the relevant parameters\n",
    "# note red noise proposals may not be accepted since IRN is different from total RN\n",
    "# would be better to use a fact like run\n",
    "chain = np.zeros((len(psrnames)*4+3,200000))\n",
    "param_list = []\n",
    "params = []\n",
    "i = 0\n",
    "for psrname in psrnames:\n",
    "    singlepsr_params = []\n",
    "    singlepsr_params.append([f'{psrname}_red_noise_gamma',f'{psrname}_red_noise_log10_A'])\n",
    "    singlepsr_params.append([f'{psrname}_dm_gp_gamma',f'{psrname}_dm_gp_log10_A'])\n",
    "    if psrname == 'J1713+0747':\n",
    "        singlepsr_params.append([f'{psrname}_exp1_log10_Amp'])\n",
    "        singlepsr_params.append([f'{psrname}_exp1_log10_tau'])\n",
    "        singlepsr_params.append([f'{psrname}_exp1_t0'])\n",
    "    param_list.extend(singlepsr_params)\n",
    "    singlepsr_params_flat = [p1 for p2 in singlepsr_params for p1 in p2]\n",
    "    params.extend(singlepsr_params_flat)\n",
    "    c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5',burn=0)\n",
    "    for p in singlepsr_params_flat:\n",
    "        chain[i] = c(p)[:200000]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_distributions(psrnames, burn=0, nbins=40,\n",
    "                                 filename=None, return_distribution=False):\n",
    "    \n",
    "    distr = []\n",
    "    \n",
    "    i = 0\n",
    "    for psrname in psrnames:\n",
    "        \n",
    "        # load core\n",
    "        c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5', burn=burn)\n",
    "        \n",
    "        # make param list\n",
    "        paramlist = []\n",
    "        paramlist.append([f'{psrname}_red_noise_gamma',f'{psrname}_red_noise_log10_A'])\n",
    "        paramlist.append([f'{psrname}_dm_gp_gamma',f'{psrname}_dm_gp_log10_A'])\n",
    "        if psrname == 'J1713+0747':\n",
    "            paramlist.append([f'{psrname}_exp1_log10_Amp'])\n",
    "            paramlist.append([f'{psrname}_exp1_log10_tau'])\n",
    "            paramlist.append([f'{psrname}_exp1_t0'])\n",
    "\n",
    "        for pl in paramlist:\n",
    "\n",
    "            if type(pl) is not list:\n",
    "\n",
    "                pl = [pl]\n",
    "\n",
    "            if len(pl) == 1:\n",
    "                idx = c.params.index(pl[0])\n",
    "\n",
    "                prior_min = float(c.priors[idx][c.priors[idx].index('pmin')+5:c.priors[idx].index(',')])\n",
    "                prior_max = float(c.priors[idx][c.priors[idx].index('pmax')+5:c.priors[idx].index(')')])\n",
    "\n",
    "                # get the bins for the histogram\n",
    "                bins = np.linspace(prior_min, prior_max, nbins)\n",
    "\n",
    "                new_distr = EmpiricalDistribution1D(pl[0], c.chain[c.burn:, idx], bins)\n",
    "\n",
    "                distr.append(new_distr)\n",
    "\n",
    "            elif len(pl) == 2:\n",
    "\n",
    "                # get the parameter indices\n",
    "                idx = [c.params.index(pl1) for pl1 in pl]\n",
    "\n",
    "                # get the bins for the histogram\n",
    "                bins = [np.linspace(float(c.priors[i][c.priors[i].index('pmin')+5:c.priors[i].index(',')]),\n",
    "                                    float(c.priors[i][c.priors[i].index('pmax')+5:c.priors[i].index(')')]),\n",
    "                                    nbins) for i in idx]\n",
    "\n",
    "                new_distr = EmpiricalDistribution2D(pl, c.chain[c.burn:, idx].T, bins)\n",
    "\n",
    "                distr.append(new_distr)\n",
    "\n",
    "            else:\n",
    "                msg = 'WARNING: only 1D and 2D empirical distributions are currently allowed.'\n",
    "                logger.warning(msg)\n",
    "\n",
    "    # save the list of empirical distributions as a pickle file\n",
    "    if filename is not None:\n",
    "        if len(distr) > 0:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(distr, f)\n",
    "\n",
    "            msg = 'The empirical distributions have been pickled to {0}.'.format(filename)\n",
    "            logger.info(msg)\n",
    "        else:\n",
    "            msg = 'WARNING: No empirical distributions were made!'\n",
    "            logger.warning(msg)\n",
    "\n",
    "    if return_distribution:\n",
    "        return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40545620",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{project_path}/empdists/dr2full_stdnoise.pkl'\n",
    "distr = make_empirical_distributions(psrnames, burn=0, nbins=40,\n",
    "                                     filename=filename, return_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b09926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59f1c7a",
   "metadata": {},
   "source": [
    "## Check ConditionalGP ECORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "psrname = 'J1939+2134'\n",
    "c = co.Core(corepath=f'{coresave_dir}/{psrname}/core.h5', burn=0)\n",
    "fname = f'{ePSR_dir}/{psrname}.hdf5'\n",
    "psr = FilePulsar(fname)\n",
    "# set up noise flags + selections\n",
    "inc_ecorr = False\n",
    "signal_names = [f'{psrname}_dm_gp',f'{psrname}_red_noise']\n",
    "colors = ['C1','C3']\n",
    "# set up DM Nfreqs\n",
    "pta = model_singlepsr_noise(psr, Tspan=952746385.6296968,\n",
    "                            # timing -  set svd false for GPs\n",
    "                            tm_svd=False,\n",
    "                            # white noise - set gp_ecorr True for GPs\n",
    "                            tnequad=True, inc_ecorr=True, gp_ecorr=True,\n",
    "                            #efeq_groups=efeq_groups_by_PTA, ecorr_groups=ecorr_groups_by_PTA,\n",
    "                            log_equad_min=-10, log_equad_max=-4,\n",
    "                            # DM\n",
    "                            dm_var=True, dm_type='gp',\n",
    "                            dmgp_kernel='diag', dm_psd='powerlaw',\n",
    "                            dm_Nfreqs=30,\n",
    "                            # solar wind\n",
    "                            dm_sw_deter=False,\n",
    "                            # dm dip\n",
    "                            dm_expdip=False, dm_expdip_basename='exp',\n",
    "                            dm_expdip_tau_min=np.log10(5), dm_expdip_tau_max=np.log10(500), \n",
    "                            # red noise\n",
    "                            log_A_min=-20, log_A_max=-11)\n",
    "for signal in pta.signals:\n",
    "    if pta.signals[signal].signal_type == 'basis':\n",
    "        pta.signals[signal].basis_combine=False\n",
    "gp = ConditionalGP(pta)\n",
    "mlv_params = {p:c(p)[c.map_idx] for p in c.params}\n",
    "mlv_GPs = gp.sample_processes(mlv_params, n=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {'B1937+21_L-wide_ASP_log10_ecorr': -6.985907827570632,\n",
    " 'B1937+21_L-wide_PUPPI_log10_ecorr': -6.933190952449128,\n",
    " 'B1937+21_Rcvr1_2_GASP_log10_ecorr': -6.951805082863183,\n",
    " 'B1937+21_Rcvr1_2_GUPPI_log10_ecorr': -6.9742651134780225,\n",
    " 'B1937+21_Rcvr_800_GASP_log10_ecorr': -8.377559128584869,\n",
    " 'B1937+21_Rcvr_800_GUPPI_log10_ecorr': -6.347443803757376,\n",
    " 'B1937+21_S-wide_ASP_log10_ecorr': -6.560243521577494,\n",
    " 'B1937+21_S-wide_PUPPI_log10_ecorr': -6.998893530255561,\n",
    " 'B1937+21_basis_ecorr_L-wide_ASP_log10_ecorr': -6.985907827570632,\n",
    " 'B1937+21_basis_ecorr_L-wide_PUPPI_log10_ecorr': -6.933190952449128,\n",
    " 'B1937+21_basis_ecorr_Rcvr1_2_GASP_log10_ecorr': -6.951805082863183,\n",
    " 'B1937+21_basis_ecorr_Rcvr1_2_GUPPI_log10_ecorr': -6.9742651134780225,\n",
    " 'B1937+21_basis_ecorr_Rcvr_800_GASP_log10_ecorr': -8.377559128584869,\n",
    " 'B1937+21_basis_ecorr_Rcvr_800_GUPPI_log10_ecorr': -6.347443803757376,\n",
    " 'B1937+21_basis_ecorr_S-wide_ASP_log10_ecorr': -6.560243521577494,\n",
    " 'B1937+21_basis_ecorr_S-wide_PUPPI_log10_ecorr': -6.998893530255561}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c827e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_GPs = gp.sample_processes(mlv_params, n=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345caef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in c.params:\n",
    "    if 'ecorr' in p:\n",
    "        print(f'{p}: {c.get_map_param(p)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aee12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = np.sum([mlv_GPs[sn] for sn in mlv_GPs if not 'ecorr' in sn], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cf19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "nu_min = np.min(psr.freqs)\n",
    "nu_max = np.max(psr.freqs)\n",
    "#mean_GPs = gp.get_mean_processes(mlv_params)\n",
    "if isinstance(correction, np.ndarray):\n",
    "    resids = psr.residuals - correction\n",
    "else:\n",
    "    resids = psr.residuals\n",
    "for marker, pta in zip(['s'], ['NANOGrav']):\n",
    "    if pta in psr.flags['pta']:\n",
    "        mask = (psr.flags['pta'] == pta)*(psr.flags['group'] != 'kaspi23')*(psr.flags['group'] != 'kaspi14')\n",
    "        ax.errorbar(psr.toas[mask]/const.day, resids[mask]*1e6, yerr=psr.toaerrs[mask]*1e6,\n",
    "                    fmt=f'{marker}k', ms=5, marker=None, mew=0, alpha=0.1, lw=1, zorder=0,\n",
    "                    label='RN+DM corrected Residuals')\n",
    "        ax.plot(psr.toas[mask]/const.day, 1e6*mlv_GPs[f'{psrname}_basis_ecorr'][mask],\n",
    "                'C1', label='ECORR realization from MLV posterior sample')\n",
    "        #ax.plot(psr.toas[mask]/const.day, 1e6*mean_GPs[f'{psrname}_basis_ecorr'][mask],\n",
    "        #        'C1', label='Sample process (MLV posterior sample)')\n",
    "        #sc = ax.scatter(psr.toas[mask]/const.day, resids[mask]*1e6, s=5, marker=marker,\n",
    "        #                c=psr.freqs[mask], cmap='Spectral', vmin=nu_min, vmax=nu_max)\n",
    "#cbar = plt.colorbar(sc)\n",
    "#cbar.set_label(r\"$\\nu$ (MHz)\")\n",
    "ax.set_xlabel(\"MJD\")\n",
    "ax.set_ylabel(r\"Residual ($\\mu s$)\")\n",
    "ax.grid(linewidth=0.3)\n",
    "if isinstance(correction, np.ndarray):\n",
    "    ax.set_title(psr.name+' Corrected, NG only')\n",
    "else:\n",
    "    ax.set_title(psr.name)\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "nu_min = np.min(psr.freqs)\n",
    "nu_max = np.max(psr.freqs)\n",
    "mean_GPs = gp.get_mean_processes(mlv_params)\n",
    "if isinstance(correction, np.ndarray):\n",
    "    resids = psr.residuals - correction\n",
    "else:\n",
    "    resids = psr.residuals\n",
    "for marker, pta in zip(['s'], ['NANOGrav']):\n",
    "    if pta in psr.flags['pta']:\n",
    "        mask = (psr.flags['pta'] == pta)*(psr.flags['group'] != 'kaspi23')*(psr.flags['group'] != 'kaspi14')\n",
    "        ax.errorbar(psr.toas[mask]/const.day, resids[mask]*1e6, yerr=psr.toaerrs[mask]*1e6,\n",
    "                    fmt=f'{marker}k', ms=5, marker=None, mew=0, alpha=0.1, lw=1, zorder=0,\n",
    "                    label='RN+DM corrected Residuals')\n",
    "        ax.plot(psr.toas[mask]/const.day, 1e7*mean_GPs[f'{psrname}_basis_ecorr'][mask],\n",
    "                'C1', label=r'$10 \\times$ ECORR realization from MLV posterior sample')\n",
    "        #ax.plot(psr.toas[mask]/const.day, 1e7*mean_GPs[f'{psrname}_basis_ecorr'][mask],\n",
    "        #        'C1', label='Sample process (MLV posterior sample)')\n",
    "        #sc = ax.scatter(psr.toas[mask]/const.day, resids[mask]*1e6, s=5, marker=marker,\n",
    "        #                c=psr.freqs[mask], cmap='Spectral', vmin=nu_min, vmax=nu_max)\n",
    "#cbar = plt.colorbar(sc)\n",
    "#cbar.set_label(r\"$\\nu$ (MHz)\")\n",
    "ax.set_xlabel(\"MJD\")\n",
    "ax.set_ylabel(r\"Residual ($\\mu s$)\")\n",
    "ax.grid(linewidth=0.3)\n",
    "if isinstance(correction, np.ndarray):\n",
    "    ax.set_title(psr.name+' Corrected, NG only')\n",
    "else:\n",
    "    ax.set_title(psr.name)\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b2607",
   "metadata": {},
   "source": [
    "# Compare different versions of GP reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = ConditionalGP(pta, tm_params=['DM','DM1','DM2'], psr=psr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define processes\n",
    "n_realizations = 500\n",
    "signal_names = [f'{psrname}_basis_ecorr',f'{psrname}_dm_gp',\n",
    "                f'{psrname}_red_noise',f'{psrname}_linear_timing_model']\n",
    "colors = ['C0','C1','C3','C4']\n",
    "idxs = np.random.choice(np.arange(len(c('lnpost'))), n_realizations)\n",
    "idxs[-1] = c.map_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f619a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signals = dict.fromkeys(signal_names)\n",
    "\n",
    "for i in tqdm.tqdm(range(n_realizations)):\n",
    "    idx = idxs[i]\n",
    "    params = {p:c(p)[idx] for p in c.params}\n",
    "    GPs = gp.sample_processes(params, n=1)[0]\n",
    "\n",
    "    for j, signal_name in enumerate(signal_names):\n",
    "        if i == 0:\n",
    "            signals[signal_name] = np.zeros((n_realizations,len(psr.toas)))\n",
    "        if signal_names[j] == f'{psrname}_dm_gp':\n",
    "            scaling = 1e15*const.DM_K*psr.freqs**2 # units of 1e-3 pc/cm^3\n",
    "            add = 0#GPs[f'{psrname}_DM'] + GPs[f'{psrname}_DM1'] + GPs[f'{psrname}_DM2']\n",
    "        else:\n",
    "            scaling = 1e6 # microseconds\n",
    "            add = 0\n",
    "        signals[signal_name][i] = scaling*(GPs[signal_name] + add)\n",
    "        #ax[i].plot(psr.toas/const.day, scaling*(GPs[signal_names[i]] + add), alpha=0.02, color=colors[i])\n",
    "        #ax[i].errorbar(x=psr.toas/const.day, y=np.mean(scaling*GPs[signal_name]*1e6),\n",
    "        #               yerr=2*np.std(scaling*GPs[signal_name]*1e6), color='k')\n",
    "\n",
    "# plot processes\n",
    "ngb = [\"ASP\", \"GASP\", \"GUPPI\", \"PUPPI\", \"YUPPI\"]\n",
    "fig, ax = plt.subplots(len(signal_names),1,figsize=(8,2*len(signal_names)),sharex=True)\n",
    "for i, signal_name in enumerate(signal_names):\n",
    "    units = r'($\\mu$s)'\n",
    "    mask = np.ones(len(psr.toas),dtype=bool)\n",
    "    if signal_name == f'{psrname}_dm_gp':\n",
    "        units = r'($10^{-3}$ pc/cm$^3$)'\n",
    "    elif signal_name == f'{psrname}_basis_ecorr':\n",
    "        mask = [i for i, flag in enumerate(psr.flags['group']) if\n",
    "                any(ngb_entry in flag for ngb_entry in ngb)]\n",
    "        #mask = [i for i, flag in enumerate(psr.flags['group']) if flag in ngb]\n",
    "        #mask = np.sum([psr.flags['group'] == flag for flag in ngb])\n",
    "    alpha=0.02\n",
    "    color=colors[i]\n",
    "    for j in range(n_realizations):\n",
    "        if j == n_realizations-1:\n",
    "            alpha=1\n",
    "            color='k'\n",
    "        ax[i].plot(psr.toas[mask]/const.day,\n",
    "                   signals[signal_name][j][mask]-np.mean(signals[signal_name][j][mask]),\n",
    "                   alpha=alpha, color=color)\n",
    "    ax[i].set_ylabel(f'{signal_name.replace(f\"{psrname}_\",\"\")} {units}')\n",
    "    ax[i].grid(lw=0.3)\n",
    "ax[-1].set_xlabel('MJD')\n",
    "xlim = ax[0].get_xlim()\n",
    "fig.suptitle(f'{psrname} processes using ConditionalGP')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0)\n",
    "#fig.savefig(f'{figsave}/GPs.png')\n",
    "\n",
    "# plot ecorrs\n",
    "ptas = np.unique(psr.flags['pta'])\n",
    "if 'NANOGrav' in psr.flags['pta']:\n",
    "    fig, ax = plt.subplots(figsize=(8,3))\n",
    "    ecorr_med = np.median(signals[f'{psrname}_basis_ecorr'], axis=0)\n",
    "    flags_select = np.unique(psr.flags['group'][psr.flags['pta'] == 'NANOGrav'])\n",
    "    for j, flag in enumerate([flag for flag in flags_select if\n",
    "                              any(ngb_entry in flag for ngb_entry in ngb)]):\n",
    "        mask = psr.flags['group'] == flag\n",
    "        ax.plot(psr.toas[mask]/const.day, ecorr_med[mask],'.', ms=2, label=flag)\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.set_ylabel(f'NANOGrav: '+r'$\\Delta t_{\\rm{ECORR}}$ ($\\mu s$)')\n",
    "    ax.legend(fontsize='small')\n",
    "    ax.set_xlabel('MJD')\n",
    "    ax.set_title(f'ECORR | PSR {psrname} | ConditionalGP', fontsize='small')\n",
    "    ax.set_xlim(xlim)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    #fig.savefig(f'{figsave}/ECORRs.png')\n",
    "\n",
    "# mlv correction\n",
    "correction = np.sum([GPs[sn] for sn in signal_names], axis=0)\n",
    "pu.plot_resids(psr, correction=correction, correction_label='_enterprise_ConditionalGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = Signal_Reconstruction([psr], pta, core=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_ecorr = np.zeros((n_realizations,len(psr.toas)))\n",
    "lf_RN = np.zeros((n_realizations,len(psr.toas)))\n",
    "lf_DM = np.zeros((n_realizations,len(psr.toas)))\n",
    "lf_TM = np.zeros((n_realizations,len(psr.toas)))\n",
    "for i in tqdm.tqdm(range(n_realizations)):\n",
    "    lf_ecorr[i] = gp.reconstruct_signal(gp_type='basis_ecorr',idx=idxs[0])[psrname]\n",
    "    lf_RN[i] = gp.reconstruct_signal(gp_type='red_noise',idx=idxs[0])[psrname]\n",
    "    lf_DM[i] = gp.reconstruct_signal(gp_type='dm_gp',idx=idxs[0])[psrname]\n",
    "    lf_TM[i] = gp.reconstruct_signal(gp_type='timing',idx=idxs[0])[psrname]\n",
    "signals_lf = {f'{psrname}_basis_ecorr':1e6*lf_ecorr,\n",
    "              f'{psrname}_dm_gp':1e15*const.DM_K*psr.freqs**2*lf_DM,\n",
    "              f'{psrname}_red_noise':1e6*lf_RN,\n",
    "              f'{psrname}_linear_timing_model':1e6*lf_TM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093b7a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot processes\n",
    "ngb = [\"ASP\", \"GASP\", \"GUPPI\", \"PUPPI\", \"YUPPI\"]\n",
    "fig, ax = plt.subplots(len(signal_names),1,figsize=(8,2*len(signal_names)),sharex=True)\n",
    "for i, signal_name in enumerate(signal_names):\n",
    "    units = r'($\\mu$s)'\n",
    "    mask = np.ones(len(psr.toas),dtype=bool)\n",
    "    if signal_name == f'{psrname}_dm_gp':\n",
    "        units = r'($10^{-3}$ pc/cm$^3$)'\n",
    "    elif signal_name == f'{psrname}_basis_ecorr':\n",
    "        mask = [i for i, flag in enumerate(psr.flags['group']) if\n",
    "                any(ngb_entry in flag for ngb_entry in ngb)]\n",
    "        #mask = [i for i, flag in enumerate(psr.flags['group']) if flag in ngb]\n",
    "        #mask = np.sum([psr.flags['group'] == flag for flag in ngb])\n",
    "    alpha = 0.02\n",
    "    color = colors[i]\n",
    "    for j in range(n_realizations):\n",
    "        if j == n_realizations-1:\n",
    "            alpha=1\n",
    "            color='k'\n",
    "        ax[i].plot(psr.toas[mask]/const.day,\n",
    "                   signals_lf[signal_name][j][mask]-np.mean(signals_lf[signal_name][j][mask]),\n",
    "                   alpha=alpha, color=color)\n",
    "    ax[i].set_ylabel(f'{signal_name.replace(f\"{psrname}_\",\"\")} {units}')\n",
    "    ax[i].grid(lw=0.3)\n",
    "ax[-1].set_xlabel('MJD')\n",
    "xlim = ax[0].get_xlim()\n",
    "fig.suptitle(f'{psrname} processes using SignalReconstruction')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0)\n",
    "#fig.savefig(f'{figsave}/GPs.png')\n",
    "\n",
    "# plot ecorrs\n",
    "if 'NANOGrav' in psr.flags['pta']:\n",
    "    fig, ax = plt.subplots(figsize=(8,3))\n",
    "    ecorr_med = np.median(signals_lf[f'{psrname}_basis_ecorr'], axis=0)\n",
    "    flags_select = np.unique(psr.flags['group'][psr.flags['pta'] == 'NANOGrav'])\n",
    "    for j, flag in enumerate([flag for flag in flags_select if\n",
    "                              any(ngb_entry in flag for ngb_entry in ngb)]):\n",
    "        mask = psr.flags['group'] == flag\n",
    "        ax.plot(psr.toas[mask]/const.day, ecorr_med[mask],'.', ms=2, label=flag)\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.set_ylabel(f'NANOGrav: '+r'$\\Delta t_{\\rm{ECORR}}$ ($\\mu s$)')\n",
    "    ax.legend(fontsize='small')\n",
    "    ax.set_xlabel('MJD')\n",
    "    ax.set_title(f'ECORR | PSR {psrname} | SignalReconstruction', fontsize='small')\n",
    "    ax.set_xlim(xlim)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# mlv correction\n",
    "correction = gp.reconstruct_signal(gp_type='all', mlv=True)[psrname]\n",
    "pu.plot_resids(psr, correction=correction, correction_label='_la_forge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b3e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b2f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a0629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa702c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f07f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define my own version of Signal_Reconstruction for debugging...\n",
    "class Signal_Reconstruction():\n",
    "    '''\n",
    "    Class for building Gaussian process realizations from enterprise models.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, psrs, pta, chain=None, burn=None,\n",
    "                 p_list='all', core=None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        psrs : list\n",
    "            A list of enterprise.pulsar.Pulsar objects.\n",
    "\n",
    "        pta : enterprise.signal_base.PTA\n",
    "            The PTA object from enterprise that contains the signals for making\n",
    "            realizations.\n",
    "\n",
    "        chain : array\n",
    "            Array which contains chain samples from Bayesian analysis.\n",
    "\n",
    "        burn : int\n",
    "            Length of burn.\n",
    "\n",
    "        p_list : list of str, optional\n",
    "            A list of pulsar names that dictates which pulsar signals to\n",
    "            reproduce. Useful when looking at a full PTA.\n",
    "\n",
    "        core : la_forge.core.Core, optional\n",
    "            A core which contains the same information as the chain of samples.\n",
    "\n",
    "        '''\n",
    "        if not isinstance(psrs, list):\n",
    "            psrs = [psrs]\n",
    "\n",
    "        self.psrs = psrs\n",
    "        self.pta = pta\n",
    "        self.p_names = [psrs[ii].name for ii in range(len(psrs))]\n",
    "\n",
    "        if chain is None and core is None:\n",
    "            raise ValueError('Must provide a chain or a la_forge.Core object.')\n",
    "        if chain is None and core is not None:\n",
    "            chain = core.chain\n",
    "            burn = core.burn\n",
    "\n",
    "        self.chain = chain\n",
    "        if burn is None:\n",
    "            self.burn = int(0.25*chain.shape[0])\n",
    "        else:\n",
    "            self.burn = burn\n",
    "\n",
    "        self.DM_K = DM_K\n",
    "        self.mlv_idx = np.argmax(chain[:, -4])\n",
    "        self.mlv_params = self.sample_posterior(self.mlv_idx)\n",
    "\n",
    "        if p_list=='all':\n",
    "            p_list = self.p_names\n",
    "            p_idx = np.arange(len(self.p_names))\n",
    "\n",
    "        else:\n",
    "            if isinstance(p_list, six.string_types):\n",
    "                p_idx = [self.p_names.index(p_list)]\n",
    "                p_list = [p_list]\n",
    "\n",
    "            elif isinstance(p_list[0], six.string_types):\n",
    "                p_idx = [self.p_names.index(p) for p in p_list]\n",
    "\n",
    "            elif isinstance(p_list[0], int):\n",
    "                p_idx = p_list\n",
    "                p_list = self.p_names\n",
    "\n",
    "        # find basis indices\n",
    "        self.gp_idx = OrderedDict()\n",
    "        self.common_gp_idx = OrderedDict()\n",
    "        self.gp_freqs = OrderedDict()\n",
    "        self.shared_sigs = OrderedDict()\n",
    "        self.gp_types = []\n",
    "        Ntot = 0\n",
    "        for idx, pname in enumerate(self.p_names):\n",
    "            sc = self.pta._signalcollections[idx]\n",
    "            if sc.psrname==pname:\n",
    "                pass\n",
    "            else:\n",
    "                raise KeyError('Pulsar name from signal collection does '\n",
    "                               'not match name from provided list.')\n",
    "\n",
    "            phi_dim = sc.get_phi(params=self.mlv_params).shape[0]\n",
    "            if pname not in p_list:\n",
    "                pass\n",
    "            else:\n",
    "                self.gp_idx[pname] = OrderedDict()\n",
    "                self.common_gp_idx[pname] = OrderedDict()\n",
    "                self.gp_freqs[pname] = OrderedDict()\n",
    "                ntot = 0\n",
    "                # all_freqs = []\n",
    "                all_bases = []\n",
    "                basis_signals = [sig for sig in sc._signals\n",
    "                                 if sig.signal_type\n",
    "                                 in ['basis', 'common basis']]\n",
    "\n",
    "                phi_sum = np.sum([sig.get_phi(self.mlv_params).shape[0]\n",
    "                                  for sig in basis_signals])\n",
    "                if phi_dim == phi_sum:\n",
    "                    shared_bases=False\n",
    "                else:\n",
    "                    shared_bases=True\n",
    "\n",
    "                self.shared_sigs[pname] = OrderedDict()\n",
    "\n",
    "                for sig in basis_signals:\n",
    "                    if sig.signal_type in ['basis', 'common basis']:\n",
    "                        basis = sig.get_basis(params=self.mlv_params)\n",
    "                        nb = basis.shape[1]\n",
    "                        sig._construct_basis()\n",
    "                        if isinstance(sig._labels, dict):\n",
    "                            try:\n",
    "                                freqs = list(sig._labels[''])[::2]\n",
    "                            except TypeError:\n",
    "                                freqs = sig._labels['']\n",
    "                            except:\n",
    "                                freqs = None\n",
    "                        elif isinstance(sig._labels, (np.ndarray, list)):\n",
    "                            try:\n",
    "                                freqs = list(sig._labels)[::2]\n",
    "                            except TypeError:\n",
    "                                freqs = sig._labels\n",
    "\n",
    "                        # This was because svd timing bases weren't named originally.\n",
    "                        # Maybe no longer needed.\n",
    "                        if sig.signal_id=='':\n",
    "                            ky = 'timing_model'\n",
    "                        else:\n",
    "                            ky = sig.signal_id\n",
    "\n",
    "                        if ky not in self.gp_types:\n",
    "                            self.gp_types.append(ky)\n",
    "\n",
    "                        self.gp_freqs[pname][ky] = freqs\n",
    "\n",
    "                        if shared_bases:\n",
    "                            # basis = basis.tolist()\n",
    "                            check = [np.array_equal(basis, M) for M in all_bases]\n",
    "                            if any(check):\n",
    "                                b_idx = check.index(True)\n",
    "                                # b_idx = all_bases.index(basis)\n",
    "                                b_key = list(self.gp_idx[pname].keys())[b_idx]\n",
    "                                self.shared_sigs[pname][ky] = b_key\n",
    "                                self.gp_idx[pname][ky] = self.gp_idx[pname][b_key]\n",
    "                                # TODO Fix the common signal idx collector!!!\n",
    "                                if sig.signal_type == 'common basis':\n",
    "                                    self.common_gp_idx[pname][ky] = np.arange(Ntot+ntot, nb+Ntot+ntot)\n",
    "\n",
    "                            else:\n",
    "                                self.gp_idx[pname][ky] = np.arange(ntot, nb+ntot)\n",
    "                                if sig.signal_type == 'common basis':\n",
    "                                    self.common_gp_idx[pname][ky] = np.arange(Ntot+ntot, nb+Ntot+ntot)\n",
    "\n",
    "                                all_bases.append(basis)\n",
    "                                ntot += nb\n",
    "                        else:\n",
    "                            self.gp_idx[pname][ky] = np.arange(ntot, nb+ntot)\n",
    "                            if sig.signal_type == 'common basis':\n",
    "                                self.common_gp_idx[pname][ky] = np.arange(Ntot+ntot, nb+Ntot+ntot)\n",
    "\n",
    "                            ntot += nb\n",
    "\n",
    "            Ntot += phi_dim\n",
    "        self.p_list = p_list\n",
    "        self.p_idx = p_idx\n",
    "\n",
    "    def reconstruct_signal(self, gp_type='achrom_rn', det_signal=False,\n",
    "                           mlv=False, idx=None, condition=False, eps=1e-16):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        gp_type : str, {'achrom_rn','gw','DM','none','all',timing parameters}\n",
    "            Type of gaussian process signal to be reconstructed. In addition\n",
    "            any GP in `psr.fitpars` or `Signal_Reconstruction.gp_types` may be\n",
    "            called.\n",
    "\n",
    "            ['achrom_rn','red_noise'] : Return the achromatic red noise.\n",
    "\n",
    "            ['DM'] : Return the timing-model parts of dispersion model.\n",
    "\n",
    "            [timing parameters] : Any of the timing parameters from the linear timing model. A list is available as `psr.fitpars`.\n",
    "\n",
    "            ['timing'] : Return the entire timing model.\n",
    "\n",
    "            ['gw'] : Gravitational wave signal. Works with common process in full PTAs.\n",
    "\n",
    "            ['none'] : Returns no Gaussian processes. Meant to be used for returning only a deterministic signal.\n",
    "\n",
    "            ['all'] : Returns all Gaussian processes.\n",
    "\n",
    "        det_signal : bool\n",
    "            Whether to include the deterministic signals in the reconstruction.\n",
    "\n",
    "        mlv : bool\n",
    "            Whether to use the maximum likelihood value for the reconstruction.\n",
    "\n",
    "        idx : int, optional\n",
    "            Index of the chain array to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        wave : array\n",
    "            A reconstruction of a single gaussian process signal realization.\n",
    "        \"\"\"\n",
    "\n",
    "        if idx is None:\n",
    "            idx = np.random.randint(self.burn, self.chain.shape[0])\n",
    "        elif mlv:\n",
    "            idx = self.mlv_idx\n",
    "\n",
    "        # get parameter dictionary\n",
    "        params = self.sample_posterior(idx)\n",
    "        self.idx = idx\n",
    "        wave = {}\n",
    "\n",
    "        TNrs, TNTs, phiinvs, Ts = self._get_matrices(params=params)\n",
    "\n",
    "        for (p_ct, psrname, d, TNT, phiinv, T) in zip(self.p_idx, self.p_list,\n",
    "                                                      TNrs, TNTs, phiinvs, Ts):\n",
    "            wave[psrname] = 0\n",
    "\n",
    "            # Add in deterministic signal if desired.\n",
    "            if det_signal:\n",
    "                wave[psrname] += self.pta.get_delay(params=params)[p_ct]\n",
    "\n",
    "            b = self._get_b(d, TNT, phiinv)\n",
    "\n",
    "            if gp_type in self.common_gp_idx[psrname].keys():\n",
    "                B = self._get_b_common(gp_type, TNrs, TNTs, params,\n",
    "                                       condition=condition, eps=eps)\n",
    "\n",
    "            # Red noise pieces\n",
    "            psr = self.psrs[p_ct]\n",
    "            if gp_type == 'none' and det_signal:\n",
    "                pass\n",
    "            elif gp_type == 'none' and not det_signal:\n",
    "                raise ValueError('Must return a GP or deterministic signal.')\n",
    "            elif gp_type == 'DM':\n",
    "                tm_key = [ky for ky in self.gp_idx[psrname].keys()\n",
    "                          if 'timing' in ky][0]\n",
    "                dmind = np.array([ct for ct, p in enumerate(psr.fitpars)\n",
    "                                  if 'DM' in p])\n",
    "                idx = self.gp_idx[psrname][tm_key][dmind]\n",
    "                wave[psrname] += np.dot(T[:, dmind], b[dmind])\n",
    "\n",
    "            elif gp_type in ['achrom_rn', 'red_noise']:\n",
    "                if 'red_noise' not in self.shared_sigs[psrname]:\n",
    "                    if 'red_noise' in self.common_gp_idx[psrname].keys():\n",
    "                        idx = self.gp_idx[psrname]['red_noise']\n",
    "                        cidx = self.common_gp_idx[psrname]['red_noise']\n",
    "                        wave[psrname] += np.dot(T[:, idx], B[cidx])\n",
    "                    else:\n",
    "                        idx = self.gp_idx[psrname]['red_noise']\n",
    "                        wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "                else:\n",
    "                    rn_sig = self.pta.get_signal('{0}_red_noise'.format(psrname))\n",
    "                    sc = self.pta._signalcollections[p_ct]\n",
    "                    phi_rn = self._shared_basis_get_phi(sc, params, rn_sig)\n",
    "                    phiinv_rn = phi_rn.inv()\n",
    "                    idx = self.gp_idx[psrname]['red_noise']\n",
    "                    b = self._get_b(d, TNT, phiinv_rn)\n",
    "                    wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "            elif gp_type == 'timing':\n",
    "                tm_key = [ky for ky in self.gp_idx[psrname].keys()\n",
    "                          if 'timing' in ky][0]\n",
    "                idx = self.gp_idx[psrname][tm_key]\n",
    "                wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "            elif gp_type in psr.fitpars:\n",
    "                if any([ky for ky in self.gp_idx[psrname].keys()\n",
    "                        if 'svd' in ky]):\n",
    "                    raise ValueError('The SVD decomposition does not allow '\n",
    "                                     'reconstruction of the timing model '\n",
    "                                     'gaussian process realizations '\n",
    "                                     'individually.')\n",
    "\n",
    "                tm_key = [ky for ky in self.gp_idx[psrname].keys()\n",
    "                          if 'timing' in ky][0]\n",
    "                dmind = np.array([ct for ct, p in enumerate(psr.fitpars)\n",
    "                                  if gp_type in p])\n",
    "                idx = self.gp_idx[psrname][tm_key][dmind]\n",
    "                wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "            elif gp_type == 'all':\n",
    "                wave[psrname] += np.dot(T, b)\n",
    "            elif gp_type == 'gw':\n",
    "                if 'red_noise_gw' not in self.shared_sigs[psrname]:\n",
    "                    # Parse whether it is a common signal.\n",
    "                    if 'red_noise_gw' in self.common_gp_idx[psrname].keys():\n",
    "                        idx = self.gp_idx[psrname]['gw']\n",
    "                        cidx = self.common_gp_idx[psrname]['gw']\n",
    "                        wave[psrname] += np.dot(T[:, idx], B[cidx])\n",
    "                    else:  # If not common use pulsar Phi\n",
    "                        idx = self.gp_idx[psrname]['gw']\n",
    "                        wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "                # Need to make our own phi when shared...\n",
    "                else:\n",
    "                    gw_sig = self.pta.get_signal('{0}_gw'.format(psrname))\n",
    "                    # [sig for sig\n",
    "                    #           in self.pta._signalcollections[p_ct]._signals\n",
    "                    #           if sig.signal_id=='red_noise_gw'][0]\n",
    "                    # phi_gw = gw_sig.get_phi(params=params)\n",
    "                    sc = self.pta._signalcollections[p_ct]\n",
    "                    phi_gw = self._shared_basis_get_phi(sc, params, gw_sig)\n",
    "                    # phiinv_gw = gw_sig.get_phiinv(params=params)\n",
    "                    phiinv_gw = phi_gw.inv()\n",
    "                    idx = self.gp_idx[psrname]['red_noise_gw']\n",
    "                    # b = self._get_b(d[idx], TNT[idx,idx], phiinv_gw)\n",
    "                    # wave[psrname] += np.dot(T[:,idx], b)\n",
    "                    b = self._get_b(d, TNT, phiinv_gw)\n",
    "                    wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "            elif gp_type in self.gp_types:\n",
    "                try:\n",
    "                    if gp_type in self.common_gp_idx[psrname].keys():\n",
    "                        idx = self.gp_idx[psrname][gp_type]\n",
    "                        cidx = self.common_gp_idx[psrname][gp_type]\n",
    "                        wave[psrname] += np.dot(T[:, idx], B[cidx])\n",
    "                    else:\n",
    "                        idx = self.gp_idx[psrname][gp_type]\n",
    "                        wave[psrname] += np.dot(T[:, idx], b[idx])\n",
    "                except IndexError:\n",
    "                    raise IndexError('Index is out of range. '\n",
    "                                     'Maybe the basis for this is shared.')\n",
    "            else:\n",
    "                err_msg = '{0} is not an available gp_type. '.format(gp_type)\n",
    "                err_msg += 'Available gp_types '\n",
    "                err_msg += 'include {0}'.format(self.gp_types)\n",
    "                raise ValueError(err_msg)\n",
    "\n",
    "        return wave\n",
    "\n",
    "    def _get_matrices(self, params):\n",
    "        TNrs = self.pta.get_TNr(params)\n",
    "        TNTs = self.pta.get_TNT(params)\n",
    "        phiinvs = self.pta.get_phiinv(params, logdet=False)  # ,method='partition')\n",
    "        Ts = self.pta.get_basis(params)\n",
    "\n",
    "        # The following takes care of common, correlated signals.\n",
    "        if TNTs[0].shape[0]<phiinvs[0].shape[0]:\n",
    "            phiinvs = self._div_common_phiinv(TNTs, params)\n",
    "\n",
    "        # Excise pulsars if p_list not 'all'.\n",
    "        if len(self.p_list)<len(self.p_names):\n",
    "            TNrs = self._subset_psrs(TNrs, self.p_idx)\n",
    "            TNTs = self._subset_psrs(TNTs, self.p_idx)\n",
    "            phiinvs = self._subset_psrs(phiinvs, self.p_idx)\n",
    "            Ts = self._subset_psrs(Ts, self.p_idx)\n",
    "\n",
    "        return TNrs, TNTs, phiinvs, Ts\n",
    "\n",
    "    def _get_b(self, d, TNT, phiinv):\n",
    "        Sigma = TNT + (np.diag(phiinv) if phiinv.ndim == 1 else phiinv)\n",
    "        try:\n",
    "            u, s, _ = sl.svd(Sigma)\n",
    "            mn = np.dot(u, np.dot(u.T, d)/s)\n",
    "            Li = u * np.sqrt(1/s)\n",
    "        except np.linalg.LinAlgError:\n",
    "            Q, R = sl.qr(Sigma)\n",
    "            Sigi = sl.solve(R, Q.T)\n",
    "            mn = np.dot(Sigi, d)\n",
    "            u, s, _ = sl.svd(Sigi)\n",
    "            Li = u * np.sqrt(1/s)\n",
    "\n",
    "        return mn + np.dot(Li, np.random.randn(Li.shape[0]))\n",
    "\n",
    "    def _get_b_common(self, gp_type, TNrs, TNTs, params,\n",
    "                      condition=False, eps=1e-16):\n",
    "        if condition:\n",
    "            # conditioner = [eps*np.ones_like(TNT) for TNT in TNTs]\n",
    "            # Sigma += sps.block_diag(conditioner,'csc')\n",
    "            # Sigma += eps * sps.eye(phiinv.shape[0])\n",
    "            phi = self.pta.get_phi(params)  # .astype(np.float128)\n",
    "            # phisparse = sps.csc_matrix(phi)\n",
    "            # conditioner = [eps*np.ones_like(TNT) for TNT in TNTs]\n",
    "            # phisparse += sps.block_diag(conditioner,'csc')\n",
    "            # phisparse += eps * sps.identity(phisparse.shape[0])\n",
    "            # cf = cholesky(phisparse)\n",
    "            # phiinv = cf.inv()\n",
    "\n",
    "            # u,s,vT = np.linalg.svd(phi)\n",
    "            # s_inv=np.diagflat(1/s)\n",
    "            # phiinv = np.dot(np.dot(vT.T,s_inv),u.T)\n",
    "            # print('NP Inv')\n",
    "            # q,r = np.linalg.qr(phi,mode='complete')\n",
    "            # phiinv = np.dot(np.linalg.inv(r),q.T)\n",
    "            phiinv = np.linalg.inv(phi)\n",
    "            phiinv = sps.csc_matrix(phiinv)\n",
    "        else:\n",
    "            phiinv = self.pta.get_phiinv(params, logdet=False)\n",
    "            # phiinv = sps.csc_matrix(self.pta.get_phiinv(params, logdet=False))#,\n",
    "            #   method='partition'))\n",
    "\n",
    "        sps_Sigma = sps.block_diag(TNTs, 'csc') + sps.csc_matrix(phiinv)\n",
    "        Sigma = sl.block_diag(*TNTs) + phiinv  # .astype(np.float128)\n",
    "        TNr = np.concatenate(TNrs)\n",
    "\n",
    "        ch = cholesky(sps_Sigma)\n",
    "        # mn = ch(TNr)\n",
    "        Li = sps.linalg.inv(ch.L()).todense()\n",
    "        mn = np.linalg.solve(Sigma, TNr)\n",
    "        # r = 1e30\n",
    "        # regul = np.dot(Sigma.T,Sigma) + r*np.eye(Sigma.shape[0])\n",
    "        # regul_inv = sl.inv(regul)\n",
    "        # mn = np.dot(regul_inv,np.dot(Sigma.T,TNr))\n",
    "\n",
    "        self.gp = np.random.randn(mn.shape[0])\n",
    "        L = self.common_gp_idx[self.p_list[0]][gp_type].shape[0]\n",
    "        common_gp = np.random.randn(L)\n",
    "\n",
    "        for psrname in self.p_list:\n",
    "            idxs = self.common_gp_idx[psrname][gp_type]\n",
    "            self.gp[idxs] = common_gp\n",
    "\n",
    "        B = mn + np.dot(Li, self.gp)\n",
    "\n",
    "        try:\n",
    "            B = np.array(B.tolist()[0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return B\n",
    "\n",
    "    def sample_params(self, index):\n",
    "        return {par: self.chain[index, ct] for ct, par\n",
    "                in enumerate(self.pta.param_names)}\n",
    "\n",
    "    def sample_posterior(self, samp_idx, array_params=['alphas', 'rho', 'nE']):\n",
    "        param_names = self.pta.param_names\n",
    "        if any([any([array_str in par for par in param_names])\n",
    "                for array_str in array_params]):\n",
    "            # Check for any array params and make samples appropriate shape.\n",
    "            mask = np.ones(len(param_names), dtype=bool)\n",
    "\n",
    "            array_par_dict = {}\n",
    "            for array_str in array_params:\n",
    "                # Go through each type of possible array sample.\n",
    "                mask &= [array_str not in par for par in param_names]\n",
    "                if any([array_str+'_0' in par for par in param_names]):\n",
    "                    array_par_name = [par.replace('_0', '')\n",
    "                                      for par in param_names\n",
    "                                      if array_str+'_0'in par][0]\n",
    "                    array_idxs = np.where([array_str in par\n",
    "                                           for par in param_names])[0]\n",
    "                    par_array = self.chain[samp_idx, array_idxs]\n",
    "                    array_par_dict.update({array_par_name: par_array})\n",
    "\n",
    "            par_idx = np.where(mask)[0]\n",
    "            par_sample = {param_names[p_idx]: self.chain[samp_idx, p_idx]\n",
    "                          for p_idx in par_idx}\n",
    "            par_sample.update(array_par_dict)\n",
    "\n",
    "            return par_sample\n",
    "\n",
    "        else:\n",
    "            return {par: self.chain[samp_idx, ct]\n",
    "                    for ct, par in enumerate(self.pta.param_names)}\n",
    "\n",
    "    def _subset_psrs(self, likelihood_list, p_idx):\n",
    "        return list(np.array(likelihood_list)[p_idx])\n",
    "\n",
    "    def _div_common_phiinv(self, TNTs, params):\n",
    "        phivecs = [signalcollection.get_phi(params) for\n",
    "                   signalcollection in self.pta._signalcollections]\n",
    "        return [None if phivec is None else phivec.inv(logdet=False)\n",
    "                for phivec in phivecs]\n",
    "\n",
    "    def _make_sigma(self, TNTs, phiinv):\n",
    "        return sl.block_diag(*TNTs) + phiinv\n",
    "\n",
    "    def _shared_basis_get_phi(self, sc, params, primary_signal):\n",
    "        \"\"\"Rewrite of get_phi where overlapping bases are ignored.\"\"\"\n",
    "        phi = KernelMatrix(sc._Fmat.shape[1])\n",
    "\n",
    "        idx_dict, _ = sc._combine_basis_columns(sc._signals)\n",
    "        primary_idxs = idx_dict[primary_signal]\n",
    "        # sig_types = []\n",
    "\n",
    "        # Make new list of signals with no overlapping bases\n",
    "        new_signals = []\n",
    "        for sig in idx_dict.keys():\n",
    "            if sig.signal_id==primary_signal.signal_id:\n",
    "                new_signals.append(sig)\n",
    "            elif not np.array_equal(primary_idxs, idx_dict[sig]):\n",
    "                new_signals.append(sig)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        for signal in new_signals:\n",
    "            if signal in sc._idx:\n",
    "                phi = phi.add(signal.get_phi(params), sc._idx[signal])\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def _shared_basis_get_phiinv(self, sc, params, primary_signal):\n",
    "        \"\"\"Rewrite of get_phiinv where overlapping bases are ignored.\"\"\"\n",
    "        return _shared_basis_get_phi.get_phi(sc, params, primary_signal).inv()  # noqa: F821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229dc449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ffbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resids(psr):\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    nu_min = np.min(psr.freqs)\n",
    "    nu_max = np.max(psr.freqs)\n",
    "    for marker, pta in zip(['s','o','*'], ['NANOGrav','EPTA','PPTA']):\n",
    "        if pta in psr.flags['pta']:\n",
    "            mask = psr.flags['pta'] == pta\n",
    "            ax.errorbar(psr.toas[mask]/const.day, psr.residuals[mask]*1e6, yerr=psr.toaerrs[mask]*1e6,\n",
    "                        fmt=f'{marker}k', ms=5, marker=None, mew=0, alpha=0.5, lw=1, zorder=0, label=pta)\n",
    "            sc = ax.scatter(psr.toas[mask]/const.day, psr.residuals[mask]*1e6, s=5, marker=marker,\n",
    "                            c=psr.freqs[mask], cmap='Spectral', vmin=nu_min, vmax=nu_max)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\nu$ (MHz)\")\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(r\"Residual ($\\mu s$)\")\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.set_title(psr.name)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def plot_NG_resids(psr):\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    nu_min = np.min(psr.freqs)\n",
    "    nu_max = np.max(psr.freqs)\n",
    "    for marker, pta in zip(['s'], ['NANOGrav']):\n",
    "        if pta in psr.flags['pta']:\n",
    "            mask = (psr.flags['pta'] == pta)*~(psr.flags['group'] == 'kaspi')\n",
    "            ax.errorbar(psr.toas[mask]/const.day, psr.residuals[mask]*1e6, yerr=psr.toaerrs[mask]*1e6,\n",
    "                        fmt=f'{marker}k', ms=5, marker=None, mew=0, alpha=0.5, lw=1, zorder=0, label=pta)\n",
    "            sc = ax.scatter(psr.toas[mask]/const.day, psr.residuals[mask]*1e6, s=5, marker=marker,\n",
    "                            c=psr.freqs[mask], cmap='Spectral', vmin=nu_min, vmax=nu_max)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\nu$ (MHz)\")\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(r\"Residual ($\\mu s$)\")\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.set_title(psr.name)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def plot_avg_resids(psr, resids):\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    nu_min = np.min(psr.freqs)\n",
    "    nu_max = np.max(psr.freqs)\n",
    "    for band in resids[0]:\n",
    "        #mask = resids[1][band]\n",
    "        toas = resids[0][band][:,0]\n",
    "        res = resids[0][band][:,1]\n",
    "        toaerrs = resids[0][band][:,2]\n",
    "        ax.errorbar(toas/const.day, res*1e6, yerr=toaerrs*1e6,\n",
    "                    fmt=f'sk', ms=5, marker=None, mew=0, alpha=0.5, lw=1, zorder=0)\n",
    "        sc = ax.scatter(toas/const.day, res*1e6, s=5, marker='s', label=band)\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(r\"Residual ($\\mu s$)\")\n",
    "    ax.grid(linewidth=0.3)\n",
    "    ax.set_title(psr.name)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(resids[1]['430'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = epoch_ave_resid(psr, dt=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resids[0]['430'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3999369",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = epoch_ave_resid(psr, dt=10)\n",
    "resids_corr = epoch_ave_resid(psr,\n",
    "                              correction=np.median(lf_TM,axis=0)+\n",
    "                              np.median(lf_DM,axis=0)+np.median(lf_ecorr,axis=0), dt=10)\n",
    "plot_NG_resids(psr)\n",
    "plot_avg_resids(psr, resids)\n",
    "plot_avg_resids(psr, resids_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from la_forge.utils import epoch_ave_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = epoch_ave_resid(psr, dt=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_resids(psr, resids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
